
# default basic settings for UCAgent
lang: "zh"

model_type: openai

openai:
  model_name: "<your_chat_model_name>"
  openai_api_key: "your_api_key"
  openai_api_base: "http://<your_chat_model_url>/v1"
  model_kwargs:
    stop: ["."]

embed:
  model_name: "<your_embedding_model_name>"
  openai_api_key: "your_api_key"
  openai_api_base: "http://<your_embedding_model_url>/v1"
  dims: 4096

# This is the setting for conversation summary
# Adjust the max_tokens and max_summary_tokens according to your needs and model capabilities
# Reference doc: https://langchain-ai.lang.chat/langmem/reference/short_term/#langmem.short_term.SummarizationNode
# if use_trim_mode is false (summarization mode):
#   Param: max_tokens, suggested 50% of the model's context length
# if use_trim_mode is true (trim mode):
#   Param: max_tokens, suggested 80% of the model's context length
conversation_summary:
  max_tokens: 102400
  max_summary_tokens: 1024
  use_trim_mode: true

template: unity_test

un_write_dirs:
  - "{DUT}"
  - "Guide_Doc"
write_dirs:
  - "{OUT}"

tools:
  RunTestCases:
    test_dir: "{OUT}/tests"
